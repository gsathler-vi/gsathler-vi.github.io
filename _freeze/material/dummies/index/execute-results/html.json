{
  "hash": "12127d111fcacd914ff031f3314c8abe",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Aplicação de Dummies: Desvendando o Desempenho no ENADE com Regressão Múltipla\"\nsubtitle: \"Um Guia Prático para Modelagem Econométrica\"\ndate: 11-12-2025\nauthor: \"Gabriel Sathler Victer Itaborahy\"\nlang: pt-BR\nsection-divs: true\nimage: \"image.png\"\n---\n\nMaterial apresentado na disciplina de Econometria do Curso de Ciencias Econômicas - PUC Minas\n\n[**LINK: Currículo e demais redes**](https://linktr.ee/gabrielsathler)\n\n## **1. Introdução**\n\nEste material didático foi criado com objetivo de dar um exemplo prático aos alunos de econometria a respeito a utilização de variáveis **`DUMMY`**\n\n### 1.1. O Problema: O que explica a nota no ENADE?\n\nNeste guia, investigaremos quais fatores socioeconômicos e comportamentais influenciam a nota dos estudantes de **Ciências Econômicas** em **Universidades** no Exame Nacional de Desempenho dos Estudantes (ENADE) derivado de um projeto de Iniciação Cientifica de própria autoria. Para isso, utilizaremos um modelo de regressão múltipla, com um foco especial na correta especificação de variáveis categóricas.\n\n### 1.2. Preparação do Ambiente e dos Dados\n\nPrimeiro, carregamos as bibliotecas necessárias e filtramos nossa base de dados para focar no nosso público de interesse.\n\n::: {#eae60718 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport warnings\n\n# Ignora warnings para uma saída mais limpa\nwarnings.simplefilter(\"ignore\")\n\n# Configura o estilo dos gráficos\nsns.set_theme(style=\"whitegrid\")\n\n# Carrega e filtra os dados\ntry:\n    df_completo = pd.read_parquet('dataset/01_enade.parquet')\n    df_eco = df_completo[df_completo['cod_grupo'] == 13].copy()\n    df = df_eco[df_eco['cod_ies_org'] == 1].copy()\n    print(f\"O DataFrame final contém {df.shape[0]} observações para nossa investigação.\")\nexcept FileNotFoundError:\n    print(\"Erro: Arquivo 'dataset/01_enade.parquet' não foi encontrado.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nO DataFrame final contém 28191 observações para nossa investigação.\n```\n:::\n:::\n\n\n## **2. O Desafio das Variáveis Categóricas**\n\nModelos de regressão, como o de Mínimos Quadrados Ordinários (OLS), requerem que todas as variáveis sejam numéricas. No entanto, muitas informações socioeconômicas importantes são, por natureza, categóricas. Simplesmente atribuir números sequenciais (e.g., 1 para a primeira faixa de renda, 2 para a segunda) é uma abordagem incorreta, pois impõe uma relação linear que raramente existe na realidade.\n\n## **3. A Solução: Variáveis Dummy**\n\n**Obs.: Focaremos o exemplo na variável de `Faixa de Renda` neste material mas se aplica as demais variáveis.**\n\n### 3.1. O que são Dummies?\n\nA solução correta é transformar cada categoria em uma **variável dummy** (ou indicadora). Uma dummy é uma variável binária que assume o valor `1` se uma característica está presente e `0` caso contrário.\n\n$D_i = \\begin{cases} 1 & \\text{se o indivíduo } i \\text{ possui a característica} \\\\ 0 & \\text{caso contrário} \\end{cases}$\n\n### 3.2. Exemplo Prático: Transformando Variáveis\n\n#### 3.2.1. Exemplo tabela original retirada do questionário:\n\n| Aluno        | Faixa de Renda | Descrição 'Faixa de Renda' |\n|--------------|:---------------|----------------------------|\n| Gabriel      | A              | **Até 1,5 SM**             |\n| Henrique     | B              | De 1,5 a 3 SM              |\n| João Marcelo | B              | De 1,5 a 3 SM              |\n| Mylla        | D              | De 4,5 a 6 SM              |\n| Thiago       | E              | De 6 a 10 SM               |\n| Caroline     | F              | De 10 a 30 SM              |\n| Pedro        | G              | Acima de 30 SM             |\n\n#### 3.2.2. Transformação do questionário para variáveis numericas ordinais:\n\nUtilizaremos esta variável para fins didáticos posteriormente.\n\n| Aluno        | cod_renda | Descrição 'cod_renda' |\n|--------------|:----------|-----------------------|\n| Gabriel      | 1         | **Até 1,5 SM**        |\n| Henrique     | 2         | De 1,5 a 3 SM         |\n| João Marcelo | 2         | De 1,5 a 3 SM         |\n| Mylla        | 4         | De 4,5 a 6 SM         |\n| Thiago       | 5         | De 6 a 10 SM          |\n| Caroline     | 6         | De 10 a 30 SM         |\n| Pedro        | 7         | Acima de 30 SM        |\n\n#### 3.2.3. Criação de Dummies\n\nPara ilustrar, vamos ver como as variáveis **Renda Familiar** (7 categorias) e **Situação de Trabalho** (5 categorias) são transformadas.\n\n-   **Renda:** Ref: \"Até 1,5 SM\". Criamos 6 dummies (`renda_fx2` a `renda_fx7`).\n-   **Trabalho:** Ref: \"Não trabalha\". Criamos 4 dummies (`trab_eventual` a `trab_40h_mais`).\n\nA tabela abaixo mostra como a transformação funciona para estudantes hipotéticos:\n\n| Aluno | Renda Original (Categoria) | renda_fx2 | renda_fx3 | renda_fx4 | renda_fx5 | renda_fx6 | renda_fx7 |\n|---------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|\n| Gabriel | **Até 1,5 SM (Ref.)** | 0 | 0 | 0 | 0 | 0 | 0 |\n| Henrique | De 1,5 a 3 SM | 1 | 0 | 0 | 0 | 0 | 0 |\n| João Marcelo | De 1,5 a 3 SM | 1 | 0 | 0 | 0 | 0 | 0 |\n| Mylla | De 4,5 a 6 SM | 0 | 0 | 1 | 0 | 0 | 0 |\n| Thiago | De 6 a 10 SM | 0 | 0 | 0 | 1 | 0 | 0 |\n| Caroline | De 10 a 30 SM | 0 | 0 | 0 | 0 | 1 | 0 |\n| Pedro | Acima de 30 SM | 0 | 0 | 0 | 0 | 0 | 1 |\n\nO coeficiente de cada dummy (ex: `renda_fx2`) mede o impacto daquela categoria **em comparação com a categoria de referência**.\n\n### 3.3. A Armadilha da Multicolinearidade\n\n**Regra de Ouro:** Se uma variável possui **k** categorias, criamos apenas **k-1** dummies. Se criarmos dummies para todas as *k* categorias, o modelo se torna inestimável devido à **multicolinearidade perfeita**.\n\n## **4. Construção e Análise dos Modelos**\n\nPara fins didáticos, utilizaremos o modelo de regressão com estimadores de MQO (Mínimos Quadrados Ordinários).\n\n***Obs.:***\n*`O estimador robusto utilizado originalmente na pesquisa que melhor se adequa ao comportamento dos dados não será aplicado neste exemplo.`*\n\n### 4.1. O Modelo Teórico Completo\n\nNosso objetivo é modelar a nota geral ($Nota_i$) do estudante $i$ como uma função de todas as nossas características selecionadas, de forma explícita:\n\n```{=latex}\n\\begin{align}\nNota_i = \\beta_0 & + \\alpha_1 \\text{PessoasRes}_i \\\\\n& + \\theta_1 \\text{GeneroFem}\\_i \\\\\n& + \\beta_2 \\text{Preta}_i + \\beta_3 \\text{Parda}_i \\\\\n& + \\delta_2 \\text{Renda}_2 + \\delta_3 \\text{Renda}_3 + \\delta_4 \\text{Renda}_4 + \\delta_5 \\text{Renda}_5 + \\delta_6 \\text{Renda}_6 + \\delta_7 \\text{Renda}_7 \\\\\n& + \\gamma_1 \\text{TrabEventual} + \\gamma_2 \\text{Trab20h} + \\gamma_3 \\text{Trab39h} + \\gamma_4 \\text{Trab40h+} \\\\\n& + \\zeta_1 \\text{Estudo3h} + \\zeta_2 \\text{Estudo7h} + \\zeta_3 \\text{Estudo12h} + \\zeta_4 \\text{Estudo12h+} \\\\\n& + \\eta_1 \\text{Leitura2} + \\eta_2 \\text{Leitura5} + \\eta_3 \\text{Leitura8} + \\eta_4 \\text{Leitura8+} \\\\\n& + \\lambda_1 \\text{EMMaioriaPub} + \\lambda_2 \\text{EMMetadePub} + \\lambda_3 \\text{EMMaioriaPriv} \\\\\n& + \\lambda_4 \\text{EMTotalPriv} + \\lambda_5 \\text{EMExterior} + \\epsilon_i\n\\end{align}\n```\n\n### 4.2. Modelo 1: A Abordagem Correta (com Dummies)\n\nPrimeiro, estimamos o modelo de regressão utilizando o conjunto completo de dummies.\n\n::: {#b47c6ac6 .cell execution_count=2}\n``` {.python .cell-code}\n# Preparação dos Dados\ny_var = 'nt_ger'\nx_vars_dummies = [\n    'cod_pessoas_res', \n    'genero_fem',\n    'cor_preta', 'cor_parda',\n    'renda_fx2', 'renda_fx3', 'renda_fx4', 'renda_fx5', 'renda_fx6', 'renda_fx7',\n    'trab_eventual', 'trab_ate20h', 'trab_21a39h', 'trab_40h_mais',\n    'hestudo_1a3h', 'hestudo_4a7h', 'hestudo_8a12h', 'hestudo_mais12h',\n    'leitura_1a2', 'leitura_3a5', 'leitura_6a8', 'leitura_mais8',\n    'em_maioria_pub', 'em_metade_pub', 'em_maioria_priv', 'em_total_priv', 'em_brasil_exterior'\n]\ndf_reg = df[[y_var] + x_vars_dummies].copy().dropna()\ny = df_reg[y_var]\nX_dummies = sm.add_constant(df_reg[x_vars_dummies])\n\n# Estimação do Modelo\nmodelo_ols = sm.OLS(y, X_dummies)\nresultados_ols = modelo_ols.fit()\nprint(resultados_ols.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 nt_ger   R-squared:                       0.091\nModel:                            OLS   Adj. R-squared:                  0.090\nMethod:                 Least Squares   F-statistic:                     93.19\nDate:                Mon, 17 Nov 2025   Prob (F-statistic):               0.00\nTime:                        17:50:55   Log-Likelihood:            -1.0054e+05\nNo. Observations:               25077   AIC:                         2.011e+05\nDf Residuals:                   25049   BIC:                         2.014e+05\nDf Model:                          27                                         \nCovariance Type:            nonrobust                                         \n======================================================================================\n                         coef    std err          t      P>|t|      [0.025      0.975]\n--------------------------------------------------------------------------------------\nconst                 34.5236      0.411     83.981      0.000      33.718      35.329\ncod_pessoas_res       -0.8105      0.054    -14.880      0.000      -0.917      -0.704\ngenero_fem            -3.2476      0.175    -18.569      0.000      -3.590      -2.905\ncor_preta             -1.6245      0.351     -4.634      0.000      -2.312      -0.937\ncor_parda             -0.6946      0.202     -3.446      0.001      -1.090      -0.300\nrenda_fx2              1.3880      0.338      4.106      0.000       0.725       2.051\nrenda_fx3              2.9002      0.345      8.412      0.000       2.224       3.576\nrenda_fx4              3.7961      0.367     10.330      0.000       3.076       4.516\nrenda_fx5              4.9961      0.346     14.423      0.000       4.317       5.675\nrenda_fx6              6.7019      0.359     18.682      0.000       5.999       7.405\nrenda_fx7              6.8863      0.494     13.949      0.000       5.919       7.854\ntrab_eventual         -2.4309      0.445     -5.469      0.000      -3.302      -1.560\ntrab_ate20h           -1.3955      0.423     -3.298      0.001      -2.225      -0.566\ntrab_21a39h           -2.1073      0.265     -7.937      0.000      -2.628      -1.587\ntrab_40h_mais         -3.0235      0.204    -14.805      0.000      -3.424      -2.623\nhestudo_1a3h           1.3869      0.314      4.419      0.000       0.772       2.002\nhestudo_4a7h           3.9771      0.333     11.926      0.000       3.324       4.631\nhestudo_8a12h          5.5929      0.395     14.144      0.000       4.818       6.368\nhestudo_mais12h        7.3692      0.431     17.110      0.000       6.525       8.213\nleitura_1a2            0.4798      0.275      1.742      0.082      -0.060       1.020\nleitura_3a5            0.9852      0.283      3.486      0.000       0.431       1.539\nleitura_6a8            1.7889      0.369      4.842      0.000       1.065       2.513\nleitura_mais8          1.2883      0.347      3.710      0.000       0.608       1.969\nem_maioria_pub        -1.6424      0.440     -3.729      0.000      -2.506      -0.779\nem_metade_pub         -6.2698      0.880     -7.123      0.000      -7.995      -4.544\nem_maioria_priv       -1.5785      0.424     -3.726      0.000      -2.409      -0.748\nem_total_priv          0.1622      0.198      0.820      0.412      -0.225       0.550\nem_brasil_exterior     5.7014      1.558      3.660      0.000       2.648       8.755\n==============================================================================\nOmnibus:                       76.099   Durbin-Watson:                   1.586\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               94.330\nSkew:                           0.054   Prob(JB):                     3.28e-21\nKurtosis:                       3.281   Cond. No.                         58.8\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\n#### 4.2.1 O Modelo Estimado com Coeficientes\n\nA partir da tabela acima, podemos construir a equação do modelo estimado, agora representando todas as variáveis:\n\n```{=latex}\n\\begin{align}\n\\widehat{Nota_i} = 36.38 & - 0.86 \\cdot \\text{PessoasRes}_i \\\\\n& - 3.25 \\cdot \\text{GeneroFem} \\\\\n& - 1.71 \\cdot \\text{Preta}_i - 1.30 \\cdot \\text{Parda}_i \\\\\n& + 1.39 \\cdot \\text{Renda}_2 + 2.90 \\cdot \\text{Renda}_3 + 3.80 \\cdot \\text{Renda}_4 + 5.00 \\cdot \\text{Renda}_5 + 6.70 \\cdot \\text{Renda}_6 + 6.89 \\cdot \\text{Renda}_7 \\\\\n& - 2.43 \\cdot \\text{TrabEventual} - 1.40 \\cdot \\text{Trab20h} - 2.11 \\cdot \\text{Trab39h} - 3.02 \\cdot \\text{Trab40h+} \\\\\n& + 1.39 \\cdot \\text{Estudo3h} + 3.98 \\cdot \\text{Estudo7h} + 5.59 \\cdot \\text{Estudo12h} + 7.37 \\cdot \\text{Estudo12h+} \\\\\n& + 0.48 \\cdot \\text{Leitura2} + 0.99 \\cdot \\text{Leitura5} + 1.79 \\cdot \\text{Leitura8} + 1.29 \\cdot \\text{Leitura8+} \\\\\n& - 1.64 \\cdot \\text{EMMaioriaPub} - 6.27 \\cdot \\text{EMMetadePub} - 1.58 \\cdot \\text{EMMaioriaPriv} \\\\\n& + 0.16 \\cdot \\text{EMTotalPriv} + 5.70 \\cdot \\text{EMExterior}\n\\end{align}\n```\n\n#### 4.2.2 Interpretando os Coeficientes de Renda\n\nO gráfico abaixo mostra o valor do coeficiente para cada dummy de renda.\n\n::: {#424e599b .cell execution_count=3}\n``` {.python .cell-code}\ncoefs_renda = resultados_ols.params.filter(like='renda_fx') \ncoefs_renda.index = ['1.5 a 3 SM', '3 a 4.5 SM', '4.5 a 6 SM', '6 a 10 SM', '10 a 30 SM', '> 30 SM']\n\n# 2. Adicionar a categoria de referência (impacto 0) para uma visualização completa\n# A categoria base (renda_fx1) tem um coeficiente de 0 por definição.\ndados_plot = pd.Series({'Até 1,5 SM': 0.0})\n# Adicionar os outros coeficientes com seus respectivos rótulos\nnovos_indices = ['1.5 a 3 SM', '3 a 4.5 SM', '4.5 a 6 SM', '6 a 10 SM', '10 a 30 SM', '> 30 SM']\ncoefs_renda.index = novos_indices\ndados_plot = pd.concat([dados_plot, coefs_renda])\n\n# 3. Criar o gráfico de linha\nplt.style.use('seaborn-v0_8-whitegrid') # Um estilo que favorece gráficos de linha\nplt.figure(figsize=(7, 4))\n\n# Usar sns.lineplot e adicionar marcadores ('o') para destacar cada ponto\nsns.scatterplot(x=dados_plot.index, y=dados_plot.values, marker='o', color='purple', lw=2)\nplt.title('Impacto da Renda na Nota - ', fontsize=14, pad=18)\nplt.ylabel('Impacto em Pontos (vs. \"Até 1,5 SM\")', fontsize=10)\nplt.xlabel('Faixa de Renda Familiar', fontsize=10)\nplt.xticks(rotation=45, ha='right')\nplt.ylim(bottom=-0.5) # Garante que a linha do eixo x (valor 0) seja visível\n\n# 4. Adicionar os valores em cada ponto do gráfico\nfor x, y in zip(dados_plot.index, dados_plot.values):\n    # Adiciona o texto um pouco acima do ponto para melhor visualização\n    plt.text(x=x, y=y + 0.3, s=f'{y:.2f}', ha='center', fontsize=10, weight='bold')\n\nplt.tight_layout() # Ajusta o layout para evitar que os rótulos sejam cortados\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=653 height=368}\n:::\n:::\n\n\nO modelo com dummies nos permite ver que o \"salto\" de uma faixa para outra não é constante. Podemos calcular o efeito marginal de mudar de uma faixa para a imediatamente superior:\n\n\\begin{align}\n\\Delta \\text{Efeito(Renda 2 vs 1)} &= \\hat{\\delta}_2 = 1.39 \\\\\n\\Delta \\text{Efeito(Renda 3 vs 2)} &= \\hat{\\delta}_3 - \\hat{\\delta}_2 = 2.90 - 1.39 = 1.51 \\\\\n\\Delta \\text{Efeito(Renda 4 vs 3)} &= \\hat{\\delta}_4 - \\hat{\\delta}_3 = 3.80 - 2.90 = 0.90 \\\\\n\\Delta \\text{Efeito(Renda 5 vs 4)} &= \\hat{\\delta}_5 - \\hat{\\delta}_4 = 5.00 - 3.80 = 1.20 \\\\\n\\Delta \\text{Efeito(Renda 6 vs 5)} &= \\hat{\\delta}_6 - \\hat{\\delta}_5 = 6.70 - 5.00 = 1.70 \\\\\n\\Delta \\text{Efeito(Renda 7 vs 6)} &= \\hat{\\delta}_7 - \\hat{\\delta}_6 = 6.89 - 6.70 = 0.19\n\\end{align}\n\nIsso mostra claramente a relação não-linear que o modelo ordinal não conseguiria capturar.\n\n### 4.3. Modelo 2: Um Erro Didático (Renda como Variável Ordinal)\n\nUm erro comum é pensar que as variáveis por apresntarem um comportamento aparentemente ordinal, podem ser analisada como uma variável ordinal conforme feito anteriormente com a vaariável `cod_renda`. Porém isto é um metódo errado que explicaremos a seguir.\n\nPara fins de comparação, estimamos o modelo incorreto utilizando variáveis de forma ordinal.\n\n::: {#6987e37e .cell execution_count=4}\n``` {.python .cell-code}\n# Variáveis para Modelo Ordinal\nx_vars_ordinal = [\n    'cod_pessoas_res', \n    'cor_preta', 'cor_parda', \n    'genero_fem',\n    'cod_renda',\n    'cod_trabalho',\n    'cod_hestudo', \n    'cod_leitura',\n    'em_maioria_pub', 'em_metade_pub', 'em_maioria_priv', 'em_total_priv', 'em_brasil_exterior'\n]\n\n# Preparar dados\ndf_reg_ord = df[[y_var] + x_vars_ordinal].copy().dropna()\ny_ord = df_reg_ord[y_var]\nX_ordinal = sm.add_constant(df_reg_ord[x_vars_ordinal])\n\n# Estimar modelo\nmodelo_ols_ordinal = sm.OLS(y_ord, X_ordinal)\nresultados_ols_ordinal = modelo_ols_ordinal.fit()\nprint(resultados_ols_ordinal.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 nt_ger   R-squared:                       0.091\nModel:                            OLS   Adj. R-squared:                  0.091\nMethod:                 Least Squares   F-statistic:                     189.1\nDate:                Mon, 17 Nov 2025   Prob (F-statistic):               0.00\nTime:                        17:50:55   Log-Likelihood:                -97921.\nNo. Observations:               24448   AIC:                         1.959e+05\nDf Residuals:                   24434   BIC:                         1.960e+05\nDf Model:                          13                                         \nCovariance Type:            nonrobust                                         \n======================================================================================\n                         coef    std err          t      P>|t|      [0.025      0.975]\n--------------------------------------------------------------------------------------\nconst                 33.2431      0.329    100.895      0.000      32.597      33.889\ncod_pessoas_res       -0.8365      0.055    -15.294      0.000      -0.944      -0.729\ncor_preta             -1.4632      0.355     -4.123      0.000      -2.159      -0.768\ncor_parda             -0.6861      0.203     -3.383      0.001      -1.084      -0.289\ngenero_fem            -3.2649      0.175    -18.606      0.000      -3.609      -2.921\ncod_renda              1.2706      0.056     22.533      0.000       1.160       1.381\ncod_trabalho          -0.7486      0.050    -15.121      0.000      -0.846      -0.652\ncod_hestudo            1.9822      0.087     22.831      0.000       1.812       2.152\ncod_leitura            0.3617      0.076      4.768      0.000       0.213       0.510\nem_maioria_pub        -1.7246      0.445     -3.877      0.000      -2.596      -0.853\nem_metade_pub         -6.6675      0.909     -7.333      0.000      -8.450      -4.885\nem_maioria_priv       -1.6035      0.427     -3.757      0.000      -2.440      -0.767\nem_total_priv          0.0333      0.200      0.167      0.867      -0.358       0.425\nem_brasil_exterior     5.3253      1.546      3.444      0.001       2.294       8.356\n==============================================================================\nOmnibus:                       67.742   Durbin-Watson:                   1.584\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               83.405\nSkew:                           0.049   Prob(JB):                     7.74e-19\nKurtosis:                       3.268   Cond. No.                         110.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\n#### 4.2.1 O Modelo Estimado com Coeficientes\n\nA partir da tabela acima, podemos construir a equação do modelo estimado, agora representando todas as variáveis:\n\n```{=latex}\n\\begin{align}\n\\widehat{Nota_i} = 33.59 & - 0.83 \\cdot \\text{PessoasRes}_i \\\\\n& - 3.31 \\cdot \\text{GeneroFem}_i \\\\\n& - 1.45 \\cdot \\text{Preta}_i - 0.69 \\cdot \\text{Parda}_i \\\\\n& + 1.25 \\cdot \\text{FaixaRenda}_i \\\\\n& - 0.74 \\cdot \\text{Trabalho}_i \\\\\n& + 1.98 \\cdot \\text{HorasEstudo}_i \\\\\n& + 0.36 \\cdot \\text{HorasLeitura}_i \\\\\n& - 1.64 \\cdot \\text{EMMaioriaPub}_i - 6.27 \\cdot \\text{EMMetadePub} - 1.58 \\cdot \\text{EMMaioriaPriv} \\\\\n& + 0.16 \\cdot \\text{EMTotalPriv} + 5.70 \\cdot \\text{EMExterior}\n\\end{align}\n```\n\n**Interpretação do Coeficiente Faixa de Renda:**\n\n\\begin{align}\n\\Delta \\text{Faixa de Renda} &= \\hat{\\delta} = + 1.25 \\\\\n\\end{align}\n\nA interpretação do coeficiente desta variável indica que a cada aumento de +1 na `Faixa de Renda` a pontuação cresce em + 1.25.\n\n## **5. O Veredito: Comparando os Modelos**\n\nOs gráficos a seguir ilustram a diferença fundamental entre as duas abordagens, agora empilhados verticalmente para melhor visualização.\n\n::: {#9f16c63a .cell execution_count=5}\n``` {.python .cell-code}\nfig, axes = plt.subplots(2, 1, figsize=(6, 8))\n\n# Gráfico 1: Realidade (Dummies)\nsns.lineplot(ax=axes[0], x=coefs_renda.index, y=coefs_renda.values, palette='viridis')\naxes[0].set_title('Modelo 1 - Dummies: A Realidade (Efeitos Não-Lineares)', fontsize=14)\naxes[0].set_xlabel('Faixa de Renda - Dummy', fontsize=10)\naxes[0].set_ylabel('Impacto na Nota', fontsize=10)\naxes[0].grid(True)\naxes[0].tick_params(axis='x', rotation=30)\n\n\n# Gráfico 2: Suposição Forçada (Ordinal)\nx_vals = np.arange(1, 8)\ny_vals = resultados_ols_ordinal.params['cod_renda'] * (x_vals - 1)\nsns.lineplot(ax=axes[1], x=x_vals, y=y_vals, marker='o', color='crimson', lw=2)\naxes[1].set_title('Modelo 2 - Variavel Ordinal: A Suposição Forçada (Efeito Linear)', fontsize=14)\naxes[1].set_xlabel('Código da Renda (Ordinal)', fontsize=12)\naxes[1].set_ylabel('Impacto na Nota', fontsize=10)\naxes[1].grid(True)\naxes[1].set_ylim(0, max(coefs_renda.values) * 1.1)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=568 height=752}\n:::\n:::\n\n\nPode ver que o modelo que utiliza a varavel `Faixa de Renda` de forma ordinal não consegue capturar com exatidão o impacto da variável na nota.\n\n## 6. Conclusões\n\n-   **Dummies são Essenciais:** São a forma correta de incluir variáveis categóricas em modelos de regressão.\n-   **A Regra do k-1:** Lembre-se sempre de omitir uma categoria de referência para evitar a multicolinearidade.\n-   **A Realidade não é Linear:** O uso de dummies permite que o modelo capture os efeitos não-lineares que são comuns em fenômenos socioeconômicos.\n-   **Insights do ENADE:** Fatores como renda, horas de estudo e desigualdades estruturais são preditores estatisticamente significantes do desempenho acadêmico.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}